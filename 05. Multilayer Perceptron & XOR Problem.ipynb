{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9968ddf1",
   "metadata": {
    "papermill": {
     "duration": 0.003096,
     "end_time": "2025-08-30T04:28:56.928239",
     "exception": false,
     "start_time": "2025-08-30T04:28:56.925143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center>**Lab Sheet-5**</center>\n",
    "# <center>**Multilayer Perceptron & XOR Problem**</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4420fdd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T04:28:56.935471Z",
     "iopub.status.busy": "2025-08-30T04:28:56.934571Z",
     "iopub.status.idle": "2025-08-30T04:28:56.942466Z",
     "shell.execute_reply": "2025-08-30T04:28:56.941535Z"
    },
    "papermill": {
     "duration": 0.012776,
     "end_time": "2025-08-30T04:28:56.943916",
     "exception": false,
     "start_time": "2025-08-30T04:28:56.931140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "np.random.seed(42)\n",
    "os.makedirs(\"lab5_plots\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a38e0735",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T04:28:56.950156Z",
     "iopub.status.busy": "2025-08-30T04:28:56.949883Z",
     "iopub.status.idle": "2025-08-30T04:28:56.956187Z",
     "shell.execute_reply": "2025-08-30T04:28:56.955299Z"
    },
    "papermill": {
     "duration": 0.011218,
     "end_time": "2025-08-30T04:28:56.957817",
     "exception": false,
     "start_time": "2025-08-30T04:28:56.946599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def sigmoid(x): return 1 / (1 + np.exp(-x))\n",
    "def dsigmoid(x): return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def relu(x): return np.maximum(0, x)\n",
    "def drelu(x): return (x > 0).astype(float)\n",
    "\n",
    "def tanh(x): return np.tanh(x)\n",
    "def dtanh(x): return 1 - np.tanh(x)**2\n",
    "\n",
    "# Dataset: XOR truth table\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])   # target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a98b33",
   "metadata": {
    "papermill": {
     "duration": 0.002315,
     "end_time": "2025-08-30T04:28:56.962755",
     "exception": false,
     "start_time": "2025-08-30T04:28:56.960440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**1. Build a Multilayer Perceptron (MLP) with one hidden layer in NumPy.** \n",
    "\n",
    "**2. Train the MLP to solve the XOR problem.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae31ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T04:28:56.969271Z",
     "iopub.status.busy": "2025-08-30T04:28:56.968583Z",
     "iopub.status.idle": "2025-08-30T04:28:57.933382Z",
     "shell.execute_reply": "2025-08-30T04:28:57.931982Z"
    },
    "papermill": {
     "duration": 0.96978,
     "end_time": "2025-08-30T04:28:57.935034",
     "exception": false,
     "start_time": "2025-08-30T04:28:56.965254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] loss=0.6955\n",
      "[1000] loss=0.6928\n",
      "[2000] loss=0.4331\n",
      "[3000] loss=0.3586\n",
      "[4000] loss=0.3526\n",
      "Final predictions (sigmoid hidden):\n",
      "[0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "class MLP:\n",
    "    def __init__(self, n_in, n_hidden, n_out, activation=\"sigmoid\", lr=0.1):\n",
    "        self.n_in, self.n_hidden, self.n_out = n_in, n_hidden, n_out\n",
    "        self.lr = lr\n",
    "        # weight init small random\n",
    "        self.W1 = np.random.randn(n_in, n_hidden) * 0.5\n",
    "        self.b1 = np.zeros((1, n_hidden))\n",
    "        self.W2 = np.random.randn(n_hidden, n_out) * 0.5\n",
    "        self.b2 = np.zeros((1, n_out))\n",
    "\n",
    "        if activation == \"sigmoid\":\n",
    "            self.act, self.dact = sigmoid, dsigmoid\n",
    "        elif activation == \"relu\":\n",
    "            self.act, self.dact = relu, drelu\n",
    "        elif activation == \"tanh\":\n",
    "            self.act, self.dact = tanh, dtanh\n",
    "        else:\n",
    "            raise ValueError(\"unknown activation\")\n",
    "\n",
    "    def forward(self, X):\n",
    "        z1 = X @ self.W1 + self.b1\n",
    "        a1 = self.act(z1)\n",
    "        z2 = a1 @ self.W2 + self.b2\n",
    "        a2 = sigmoid(z2)   # output always sigmoid for binary classification\n",
    "        return z1,a1,z2,a2\n",
    "\n",
    "    def train(self, X, y, epochs=5000, log_interval=500):\n",
    "        loss_hist = []\n",
    "        log_data = {\"W1\":[], \"W2\":[], \"a1\":[], \"out\":[]}\n",
    "\n",
    "        for ep in range(epochs):\n",
    "            z1,a1,z2,a2 = self.forward(X)\n",
    "            # binary cross-entropy loss\n",
    "            loss = -np.mean(y*np.log(a2+1e-9) + (1-y)*np.log(1-a2+1e-9))\n",
    "            loss_hist.append(loss)\n",
    "\n",
    "            # backprop\n",
    "            dz2 = a2 - y                    # derivative of BCE wrt z2\n",
    "            dW2 = a1.T @ dz2 / len(X)\n",
    "            db2 = np.mean(dz2,axis=0,keepdims=True)\n",
    "\n",
    "            da1 = dz2 @ self.W2.T\n",
    "            dz1 = da1 * self.dact(z1)\n",
    "            dW1 = X.T @ dz1 / len(X)\n",
    "            db1 = np.mean(dz1,axis=0,keepdims=True)\n",
    "\n",
    "            # update\n",
    "            self.W2 -= self.lr * dW2; self.b2 -= self.lr * db2\n",
    "            self.W1 -= self.lr * dW1; self.b1 -= self.lr * db1\n",
    "\n",
    "            # logging\n",
    "            if ep % log_interval == 0:\n",
    "                print(f\"[{ep}] loss={loss:.4f}\")\n",
    "                log_data[\"W1\"].append(self.W1.copy())\n",
    "                log_data[\"W2\"].append(self.W2.copy())\n",
    "                log_data[\"a1\"].append(a1.copy())\n",
    "                log_data[\"out\"].append(a2.copy())\n",
    "\n",
    "        return loss_hist, log_data\n",
    "\n",
    "    def predict(self, X, decision_rule=\"round\"):\n",
    "        _,_,_,a2 = self.forward(X)\n",
    "        if decision_rule==\"round\":   # threshold 0.5\n",
    "            return (a2>=0.5).astype(int)\n",
    "        elif decision_rule==\"max\":   # multi-class style: argmax\n",
    "            return (a2 == np.max(a2,axis=1,keepdims=True)).astype(int)\n",
    "        else:\n",
    "            return a2\n",
    "\n",
    "# Train with Sigmoid activation (default)\n",
    "mlp = MLP(2, 2, 1, activation=\"sigmoid\", lr=0.5)\n",
    "loss_hist, logs = mlp.train(X,y,epochs=5000,log_interval=1000)\n",
    "\n",
    "# plot loss\n",
    "plt.figure()\n",
    "plt.plot(loss_hist)\n",
    "plt.title(\"MLP on XOR (Sigmoid hidden)\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"Loss (BCE)\")\n",
    "plt.savefig(\"lab5_plots/loss_sigmoid.png\",dpi=150,bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "preds = mlp.predict(X)\n",
    "print(\"Final predictions (sigmoid hidden):\")\n",
    "print(preds.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4fc855",
   "metadata": {
    "papermill": {
     "duration": 0.002356,
     "end_time": "2025-08-30T04:28:57.940165",
     "exception": false,
     "start_time": "2025-08-30T04:28:57.937809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**3. Add logging for weights, activations, and errors over epochs.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc68290e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T04:28:57.946459Z",
     "iopub.status.busy": "2025-08-30T04:28:57.946063Z",
     "iopub.status.idle": "2025-08-30T04:28:57.952084Z",
     "shell.execute_reply": "2025-08-30T04:28:57.951168Z"
    },
    "papermill": {
     "duration": 0.010802,
     "end_time": "2025-08-30T04:28:57.953429",
     "exception": false,
     "start_time": "2025-08-30T04:28:57.942627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged sample W1 at 0, mid, final epoch:\n",
      "W1[0]:\n",
      " [[ 0.24800434 -0.06956843]\n",
      " [ 0.32348934  0.76131248]]\n",
      "W1[last]:\n",
      " [[ 4.0567694  -4.50912523]\n",
      " [ 7.65546018  7.92441388]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Logged sample W1 at 0, mid, final epoch:\")\n",
    "print(\"W1[0]:\\n\", logs[\"W1\"][0])\n",
    "print(\"W1[last]:\\n\", logs[\"W1\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b10bee",
   "metadata": {
    "papermill": {
     "duration": 0.002337,
     "end_time": "2025-08-30T04:28:57.958645",
     "exception": false,
     "start_time": "2025-08-30T04:28:57.956308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**4. Compare model accuracy with different activation functions (ReLU, Sigmoid).** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a10a8d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T04:28:57.965344Z",
     "iopub.status.busy": "2025-08-30T04:28:57.964560Z",
     "iopub.status.idle": "2025-08-30T04:28:59.747952Z",
     "shell.execute_reply": "2025-08-30T04:28:59.746889Z"
    },
    "papermill": {
     "duration": 1.788293,
     "end_time": "2025-08-30T04:28:59.749483",
     "exception": false,
     "start_time": "2025-08-30T04:28:57.961190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] loss=0.7021\n",
      "[2000] loss=0.3716\n",
      "[0] loss=0.7009\n",
      "[2000] loss=0.6931\n",
      "[0] loss=0.7025\n",
      "[2000] loss=0.3481\n",
      "Final XOR predictions by activation:\n",
      "sigmoid -> [0 1 0 1]\n",
      "relu -> [1 1 1 1]\n",
      "tanh -> [0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "acts = [\"sigmoid\",\"relu\",\"tanh\"]\n",
    "losses = {}\n",
    "final_preds = {}\n",
    "\n",
    "for act in acts:\n",
    "    mlp = MLP(2, 2, 1, activation=act, lr=0.5)\n",
    "    loss_hist,_ = mlp.train(X,y,epochs=4000,log_interval=2000)\n",
    "    losses[act] = loss_hist\n",
    "    final_preds[act] = mlp.predict(X)\n",
    "\n",
    "plt.figure()\n",
    "for act in acts:\n",
    "    plt.plot(losses[act],label=act)\n",
    "plt.title(\"Activation comparison (loss curves)\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"lab5_plots/activation_compare.png\",dpi=150,bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "print(\"Final XOR predictions by activation:\")\n",
    "for act in acts:\n",
    "    print(act, \"->\", final_preds[act].flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409bfab1",
   "metadata": {
    "papermill": {
     "duration": 0.002624,
     "end_time": "2025-08-30T04:28:59.755081",
     "exception": false,
     "start_time": "2025-08-30T04:28:59.752457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**5. Implement a custom decision rule for multi-class output handling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fa6c9ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T04:28:59.762252Z",
     "iopub.status.busy": "2025-08-30T04:28:59.761689Z",
     "iopub.status.idle": "2025-08-30T04:28:59.770869Z",
     "shell.execute_reply": "2025-08-30T04:28:59.769953Z"
    },
    "papermill": {
     "duration": 0.014297,
     "end_time": "2025-08-30T04:28:59.772223",
     "exception": false,
     "start_time": "2025-08-30T04:28:59.757926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision rule argmax: [0 1 0]\n",
      "decision rule threshold: [[1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x): return np.exp(x)/np.sum(np.exp(x),axis=1,keepdims=True)\n",
    "\n",
    "class Simple3Class:\n",
    "    def __init__(self):\n",
    "        self.W = np.array([[1,-1,0.5],\n",
    "                           [0.5,1,-1]])\n",
    "    def forward(self,X):\n",
    "        return softmax(X @ self.W)\n",
    "\n",
    "    def predict(self,X,rule=\"argmax\"):\n",
    "        probs = self.forward(X)\n",
    "        if rule==\"argmax\":\n",
    "            return np.argmax(probs,axis=1)\n",
    "        elif rule==\"threshold\":\n",
    "            return (probs>0.4).astype(int) # multi-label\n",
    "        else:\n",
    "            return probs\n",
    "\n",
    "# sample\n",
    "X3 = np.array([[1,0],[0,1],[1,1]])\n",
    "model3 = Simple3Class()\n",
    "print(\"decision rule argmax:\", model3.predict(X3,\"argmax\"))\n",
    "print(\"decision rule threshold:\", model3.predict(X3,\"threshold\"))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.477459,
   "end_time": "2025-08-30T04:29:00.193558",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-30T04:28:51.716099",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
