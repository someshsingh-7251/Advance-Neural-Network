{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dabae67",
   "metadata": {
    "papermill": {
     "duration": 0.003947,
     "end_time": "2025-08-29T16:40:59.927219",
     "exception": false,
     "start_time": "2025-08-29T16:40:59.923272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center>**Lab Sheet 10**</center>\n",
    "# <center>**Real-World Experiments & Projects**</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0fe2ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T16:40:59.936233Z",
     "iopub.status.busy": "2025-08-29T16:40:59.935819Z",
     "iopub.status.idle": "2025-08-29T16:41:09.413389Z",
     "shell.execute_reply": "2025-08-29T16:41:09.412317Z"
    },
    "papermill": {
     "duration": 9.484246,
     "end_time": "2025-08-29T16:41:09.415360",
     "exception": false,
     "start_time": "2025-08-29T16:40:59.931114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saves plots to ./lab10_plots/\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "os.makedirs(\"lab10_plots\", exist_ok=True)\n",
    "\n",
    "# ---------------------\n",
    "# Helper utilities\n",
    "# ---------------------\n",
    "def to_torch(x, dtype=torch.float32):\n",
    "    return torch.tensor(x, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ba39e",
   "metadata": {
    "papermill": {
     "duration": 0.003146,
     "end_time": "2025-08-29T16:41:09.422271",
     "exception": false,
     "start_time": "2025-08-29T16:41:09.419125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Q1. Digit classifier (0-9) using PyTorch (trained on sklearn digits)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c952b45d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T16:41:09.430501Z",
     "iopub.status.busy": "2025-08-29T16:41:09.430055Z",
     "iopub.status.idle": "2025-08-29T16:41:18.057819Z",
     "shell.execute_reply": "2025-08-29T16:41:18.056533Z"
    },
    "papermill": {
     "duration": 8.634083,
     "end_time": "2025-08-29T16:41:18.059773",
     "exception": false,
     "start_time": "2025-08-29T16:41:09.425690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/80 loss=0.1734 val_acc=0.9340\n",
      "Epoch 40/80 loss=0.0553 val_acc=0.9653\n",
      "Epoch 60/80 loss=0.0224 val_acc=0.9722\n",
      "Epoch 80/80 loss=0.0162 val_acc=0.9792\n",
      "Test accuracy=0.9722, Macro-F1=0.9719\n"
     ]
    }
   ],
   "source": [
    "\n",
    "digits = load_digits()\n",
    "X = digits.data         \n",
    "y = digits.target\n",
    "\n",
    "# small train/val/test split\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.2, random_state=1, stratify=y_trainval)\n",
    "\n",
    "# standardize\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "# pytorch dataset\n",
    "Xtr = torch.tensor(X_train_s, dtype=torch.float32)\n",
    "ytr = torch.tensor(y_train, dtype=torch.long)\n",
    "Xv  = torch.tensor(X_val_s, dtype=torch.float32)\n",
    "yv  = torch.tensor(y_val, dtype=torch.long)\n",
    "Xt  = torch.tensor(X_test_s, dtype=torch.float32)\n",
    "yt  = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim=64, hidden=64, n_classes=10, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, n_classes)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "model = SimpleMLP(input_dim=64, hidden=64, n_classes=10, dropout=0.2)\n",
    "opt = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# train \n",
    "epochs = 80\n",
    "train_losses, val_accs = [], []\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    opt.zero_grad()\n",
    "    out = model(Xtr)\n",
    "    loss = loss_fn(out, ytr)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = model(Xv).argmax(1).numpy()\n",
    "    acc = accuracy_score(y_val, val_pred)\n",
    "    val_accs.append(acc)\n",
    "    if (ep+1) % 20 == 0:\n",
    "        print(f\"Epoch {ep+1}/{epochs} loss={loss.item():.4f} val_acc={acc:.4f}\")\n",
    "\n",
    "# evaluate on test\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_logits = model(Xt)\n",
    "    test_pred = test_logits.argmax(1).numpy()\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "test_f1  = f1_score(y_test, test_pred, average='macro')\n",
    "print(f\"Test accuracy={test_acc:.4f}, Macro-F1={test_f1:.4f}\")\n",
    "\n",
    "# save plots: loss + val acc\n",
    "plt.figure()\n",
    "plt.plot(train_losses)\n",
    "plt.title(\"Training loss (digit MLP)\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\")\n",
    "plt.savefig(\"lab10_plots/loss.png\", dpi=150); plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(val_accs)\n",
    "plt.title(\"Validation accuracy (digit MLP)\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"val acc\")\n",
    "plt.savefig(\"lab10_plots/valacc.png\", dpi=150); plt.close()\n",
    "\n",
    "# save some predicted digit images (first 12 test samples)\n",
    "plt.figure(figsize=(8,6))\n",
    "for i in range(12):\n",
    "    ax = plt.subplot(3,4,i+1)\n",
    "    plt.imshow(X_test[i].reshape(8,8), cmap='gray')\n",
    "    plt.title(f\"pred:{test_pred[i]} gt:{y_test[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"some test predictions\")\n",
    "plt.savefig(\"lab10_plots/sample_preds.png\", dpi=150); plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0738d563",
   "metadata": {
    "papermill": {
     "duration": 0.003054,
     "end_time": "2025-08-29T16:41:18.066507",
     "exception": false,
     "start_time": "2025-08-29T16:41:18.063453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Q2. Neural net approximating sin(x) on [0,2Ï€]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f1ff71d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T16:41:18.075229Z",
     "iopub.status.busy": "2025-08-29T16:41:18.074698Z",
     "iopub.status.idle": "2025-08-29T16:41:19.289027Z",
     "shell.execute_reply": "2025-08-29T16:41:19.287682Z"
    },
    "papermill": {
     "duration": 1.221207,
     "end_time": "2025-08-29T16:41:19.291153",
     "exception": false,
     "start_time": "2025-08-29T16:41:18.069946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sine fit epoch 150, loss=0.013560\n",
      "Sine fit epoch 300, loss=0.005471\n",
      "Sine fit epoch 450, loss=0.005219\n",
      "Sine fit epoch 600, loss=0.005212\n"
     ]
    }
   ],
   "source": [
    "N = 200\n",
    "x = np.linspace(0, 2*np.pi, N).reshape(-1,1)\n",
    "y_sin = np.sin(x)\n",
    "\n",
    "# add some noise\n",
    "y_noisy = y_sin + 0.08*np.random.randn(*y_sin.shape)\n",
    "\n",
    "# train/val split\n",
    "x_train, x_val, y_train_s, y_val_s = train_test_split(x, y_noisy, test_size=0.2, random_state=1)\n",
    "\n",
    "# to tensors\n",
    "Xt_s = torch.tensor(x_train, dtype=torch.float32)\n",
    "Yt_s = torch.tensor(y_train_s, dtype=torch.float32)\n",
    "Xv_s  = torch.tensor(x_val, dtype=torch.float32)\n",
    "Yv_s  = torch.tensor(y_val_s, dtype=torch.float32)\n",
    "\n",
    "class SineMLP(nn.Module):\n",
    "    def __init__(self, hidden=50):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "model_sin = SineMLP(hidden=40)\n",
    "opt_sin = optim.Adam(model_sin.parameters(), lr=0.01)\n",
    "loss_fn_reg = nn.MSELoss()\n",
    "\n",
    "epochs = 600\n",
    "loss_hist = []\n",
    "for ep in range(epochs):\n",
    "    opt_sin.zero_grad()\n",
    "    out = model_sin(Xt_s)\n",
    "    loss = loss_fn_reg(out, Yt_s)\n",
    "    loss.backward()\n",
    "    opt_sin.step()\n",
    "    loss_hist.append(loss.item())\n",
    "    if (ep+1) % 150 == 0:\n",
    "        print(f\"Sine fit epoch {ep+1}, loss={loss.item():.6f}\")\n",
    "\n",
    "# evaluate on dense grid\n",
    "x_grid = np.linspace(0, 2*np.pi, 300).reshape(-1,1)\n",
    "with torch.no_grad():\n",
    "    y_pred_grid = model_sin(torch.tensor(x_grid, dtype=torch.float32)).numpy()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_grid, np.sin(x_grid), label=\"true sin(x)\")\n",
    "plt.scatter(x_train, y_train_s, s=10, alpha=0.6, label=\"train (noisy)\")\n",
    "plt.plot(x_grid, y_pred_grid, label=\"MLP fit\")\n",
    "plt.legend(); plt.title(\"sin(x) approximation\")\n",
    "plt.savefig(\"lab10_plots/sin_fit.png\", dpi=150); plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_hist)\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"MSE\")\n",
    "plt.savefig(\"lab10_plots/loss.png\", dpi=150); plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b4f78",
   "metadata": {
    "papermill": {
     "duration": 0.003325,
     "end_time": "2025-08-29T16:41:19.298412",
     "exception": false,
     "start_time": "2025-08-29T16:41:19.295087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Q3. Simple recurrent associative model (sequence Hopfield-style)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e68e89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T16:41:19.306867Z",
     "iopub.status.busy": "2025-08-29T16:41:19.306442Z",
     "iopub.status.idle": "2025-08-29T16:41:19.482083Z",
     "shell.execute_reply": "2025-08-29T16:41:19.480691Z"
    },
    "papermill": {
     "duration": 0.182063,
     "end_time": "2025-08-29T16:41:19.483959",
     "exception": false,
     "start_time": "2025-08-29T16:41:19.301896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match progression for seq0 (after noisy start): [False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "def bipolar(v): return np.where(v>0, 1, -1)\n",
    "\n",
    "# create some binary temporal patterns (short sequences of length L over D-dim)\n",
    "D = 20   # dimension of pattern vectors\n",
    "L = 6    # sequence length\n",
    "num_sequences = 3\n",
    "sequences = []\n",
    "for s in range(num_sequences):\n",
    "    seq = (np.random.rand(L, D) > 0.5).astype(int) * 1\n",
    "    seq = bipolar(seq)   # convert to -1/+1\n",
    "    sequences.append(seq)\n",
    "\n",
    "# build transition matrix W such that W * x_t -> x_{t+1} (Hebbian heteroassociative)\n",
    "W_trans = np.zeros((D, D))\n",
    "for seq in sequences:\n",
    "    for t in range(L-1):\n",
    "        x_t = seq[t].reshape(-1,1)\n",
    "        x_tp1 = seq[t+1].reshape(-1,1)\n",
    "        W_trans += (x_tp1 @ x_t.T)   # outer product x_{t+1} * x_t^T\n",
    "# Optional normalization\n",
    "W_trans /= (num_sequences*(L-1))\n",
    "\n",
    "# test recall: start from first vector and iterate\n",
    "def recall_sequence(W, x0, steps=10, noisy_flip_frac=0.0):\n",
    "    x = x0.copy()\n",
    "    if noisy_flip_frac>0:\n",
    "        idx = np.random.choice(len(x), size=int(len(x)*noisy_flip_frac), replace=False)\n",
    "        x[idx] *= -1\n",
    "    history = [x.copy()]\n",
    "    for _ in range(steps):\n",
    "        h = W @ x\n",
    "        x = np.where(h>=0, 1, -1)\n",
    "        history.append(x.copy())\n",
    "    return history\n",
    "\n",
    "# demonstrate for one stored sequence\n",
    "seq0 = sequences[0]\n",
    "start = seq0[0]\n",
    "hist = recall_sequence(W_trans, start, steps=L-1, noisy_flip_frac=0.2)\n",
    "# measure how many steps match target sequence elements\n",
    "matches = [np.array_equal(hist[t], seq0[t]) for t in range(1, len(hist))]\n",
    "print(\"match progression for seq0 (after noisy start):\", matches)\n",
    "\n",
    "# Save a small visualization: Hamming similarity over steps vs true sequence\n",
    "similarities = [ (hist[t] == seq0[t]).mean() for t in range(len(hist)) ]  # fraction equal per position\n",
    "plt.figure()\n",
    "plt.plot(similarities, marker='o')\n",
    "plt.title(\"Similarity to true sequence over recall steps\")\n",
    "plt.xlabel(\"step\"); plt.ylabel(\"fraction matching\")\n",
    "plt.savefig(\"lab10_plots/sequence_similarity.png\", dpi=150); plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff6e941",
   "metadata": {
    "papermill": {
     "duration": 0.003589,
     "end_time": "2025-08-29T16:41:19.491682",
     "exception": false,
     "start_time": "2025-08-29T16:41:19.488093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Q4. Compare MLP vs SVM (accuracy, F1, ROC-AUC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d5f56c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T16:41:19.501136Z",
     "iopub.status.busy": "2025-08-29T16:41:19.500814Z",
     "iopub.status.idle": "2025-08-29T16:41:20.038646Z",
     "shell.execute_reply": "2025-08-29T16:41:20.037335Z"
    },
    "papermill": {
     "duration": 0.544425,
     "end_time": "2025-08-29T16:41:20.040456",
     "exception": false,
     "start_time": "2025-08-29T16:41:19.496031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP -> Acc: 0.9722, Macro-F1: 0.9719, Macro ROC-AUC: 0.9983\n",
      "SVM -> Acc: 0.9750, Macro-F1: 0.9749, Macro ROC-AUC: 0.9995\n"
     ]
    }
   ],
   "source": [
    "# MLP predictions already in test_pred, test_logits\n",
    "mlp_probs = torch.nn.functional.softmax(test_logits, dim=1).numpy()\n",
    "mlp_pred = test_pred\n",
    "mlp_acc = accuracy_score(y_test, mlp_pred)\n",
    "mlp_f1  = f1_score(y_test, mlp_pred, average='macro')\n",
    "# ROC-AUC (one-vs-rest)\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(10))\n",
    "mlp_roc = roc_auc_score(y_test_bin, mlp_probs, average='macro', multi_class='ovr')\n",
    "print(f\"MLP -> Acc: {mlp_acc:.4f}, Macro-F1: {mlp_f1:.4f}, Macro ROC-AUC: {mlp_roc:.4f}\")\n",
    "\n",
    "# SVM (with probability estimates)\n",
    "svm = SVC(kernel='rbf', probability=True, gamma='scale', C=5.0, random_state=0)\n",
    "svm.fit(X_train_s, y_train)\n",
    "svm_pred = svm.predict(X_test_s)\n",
    "svm_probs = svm.predict_proba(X_test_s)\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n",
    "svm_f1  = f1_score(y_test, svm_pred, average='macro')\n",
    "svm_roc = roc_auc_score(y_test_bin, svm_probs, average='macro', multi_class='ovr')\n",
    "print(f\"SVM -> Acc: {svm_acc:.4f}, Macro-F1: {svm_f1:.4f}, Macro ROC-AUC: {svm_roc:.4f}\")\n",
    "\n",
    "# Plot ROC for class 0 vs rest as example\n",
    "fpr_m, tpr_m, _ = roc_curve(y_test_bin[:,0], mlp_probs[:,0])\n",
    "fpr_s, tpr_s, _ = roc_curve(y_test_bin[:,0], svm_probs[:,0])\n",
    "plt.figure()\n",
    "plt.plot(fpr_m, tpr_m, label=f\"MLP class 0 AUC={auc(fpr_m,tpr_m):.3f}\")\n",
    "plt.plot(fpr_s, tpr_s, label=f\"SVM class 0 AUC={auc(fpr_s,tpr_s):.3f}\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC (digit class 0 vs rest)\")\n",
    "plt.legend(); plt.savefig(\"lab10_plots/roc_class0.png\", dpi=150); plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ca881",
   "metadata": {
    "papermill": {
     "duration": 0.003563,
     "end_time": "2025-08-29T16:41:20.047852",
     "exception": false,
     "start_time": "2025-08-29T16:41:20.044289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Q5. Extract features (PCA) from images and feed to a shallow NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71590a0a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-29T16:41:20.056397Z",
     "iopub.status.busy": "2025-08-29T16:41:20.056057Z",
     "iopub.status.idle": "2025-08-29T16:41:20.721889Z",
     "shell.execute_reply": "2025-08-29T16:41:20.720719Z"
    },
    "papermill": {
     "duration": 0.672239,
     "end_time": "2025-08-29T16:41:20.723631",
     "exception": false,
     "start_time": "2025-08-29T16:41:20.051392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA-based shallow NN test acc: 0.9639\n",
      "raw-pixel shallow NN test acc: 0.9722\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=20).fit(X_train_s)\n",
    "X_train_pca = pca.transform(X_train_s)\n",
    "X_test_pca  = pca.transform(X_test_s)\n",
    "\n",
    "# small shallow NN (PyTorch) that takes PCA features\n",
    "class ShallowNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden=32, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, n_classes)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "# train on PCA features\n",
    "Xt_pca = torch.tensor(X_train_pca, dtype=torch.float32)\n",
    "yt_pca = torch.tensor(y_train, dtype=torch.long)\n",
    "Xt_pca_val = torch.tensor(pca.transform(X_val_s), dtype=torch.float32)\n",
    "\n",
    "model_pca = ShallowNN(input_dim=20, hidden=48, n_classes=10)\n",
    "opt_pca = optim.Adam(model_pca.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "for ep in range(120):\n",
    "    opt_pca.zero_grad()\n",
    "    out = model_pca(Xt_pca)\n",
    "    loss = loss_fn(out, yt_pca)\n",
    "    loss.backward(); opt_pca.step()\n",
    "# eval on test\n",
    "with torch.no_grad():\n",
    "    test_pca_logits = model_pca(torch.tensor(X_test_pca,dtype=torch.float32))\n",
    "    pred_pca = test_pca_logits.argmax(1).numpy()\n",
    "acc_pca = accuracy_score(y_test, pred_pca)\n",
    "print(f\"PCA-based shallow NN test acc: {acc_pca:.4f}\")\n",
    "\n",
    "# also train shallow NN on raw pixels (for comparison)\n",
    "Xt_raw = torch.tensor(X_train_s, dtype=torch.float32)\n",
    "model_raw = ShallowNN(input_dim=64, hidden=48, n_classes=10)\n",
    "opt_raw = optim.Adam(model_raw.parameters(), lr=0.01)\n",
    "for ep in range(120):\n",
    "    opt_raw.zero_grad()\n",
    "    out = model_raw(Xt_raw)\n",
    "    loss = loss_fn(out, yt_pca)  # note: yt_pca same labels\n",
    "    loss.backward(); opt_raw.step()\n",
    "with torch.no_grad():\n",
    "    test_raw_logits = model_raw(torch.tensor(X_test_s,dtype=torch.float32))\n",
    "    pred_raw = test_raw_logits.argmax(1).numpy()\n",
    "acc_raw = accuracy_score(y_test, pred_raw)\n",
    "print(f\"raw-pixel shallow NN test acc: {acc_raw:.4f}\")\n",
    "\n",
    "# Plot comparison bar chart\n",
    "plt.figure()\n",
    "plt.bar([\"PCA (20) NN\", \"Raw-pixel NN\", \"SVM\", \"MLP\"], [acc_pca, acc_raw, svm_acc, mlp_acc])\n",
    "plt.ylim(0,1); plt.ylabel(\"Accuracy\"); plt.title(\"Feature extraction (PCA) vs raw vs baselines\")\n",
    "plt.savefig(\"lab10_plots/feature_comp.png\", dpi=150); plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8469b2d",
   "metadata": {
    "papermill": {
     "duration": 0.003415,
     "end_time": "2025-08-29T16:41:20.730996",
     "exception": false,
     "start_time": "2025-08-29T16:41:20.727581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ---------------------\n",
    "# Summary prints and saved plots\n",
    "# ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f13e4253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T16:41:20.740482Z",
     "iopub.status.busy": "2025-08-29T16:41:20.740182Z",
     "iopub.status.idle": "2025-08-29T16:41:20.746925Z",
     "shell.execute_reply": "2025-08-29T16:41:20.745658Z"
    },
    "papermill": {
     "duration": 0.013109,
     "end_time": "2025-08-29T16:41:20.748635",
     "exception": false,
     "start_time": "2025-08-29T16:41:20.735526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP (digits) test acc, macro-F1: 0.9722222222222222 0.9718831612650204\n",
      "MLP vs SVM on digits ->\n",
      "  MLP -> Acc 0.9722, F1 0.9719, ROC-AUC 0.9983\n",
      "  SVM -> Acc 0.9750, F1 0.9749, ROC-AUC 0.9995\n",
      "PCA-based shallow NN acc: 0.9638888888888889  raw-pixel NN acc: 0.9722222222222222\n",
      "\n",
      "Saved plots (lab10_plots/):\n",
      "lab10_plots/loss.png\n",
      "lab10_plots/valacc.png\n",
      "lab10_plots/sample_preds.png\n",
      "lab10_plots/sin_fit.png\n",
      "lab10_plots/loss.png\n",
      "lab10_plots/sequence_similarity.png\n",
      "lab10_plots/roc_class0.png\n",
      "lab10_plots/feature_comp.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"MLP (digits) test acc, macro-F1:\", test_acc, test_f1)\n",
    "print(\"MLP vs SVM on digits ->\")\n",
    "print(f\"  MLP -> Acc {mlp_acc:.4f}, F1 {mlp_f1:.4f}, ROC-AUC {mlp_roc:.4f}\")\n",
    "print(f\"  SVM -> Acc {svm_acc:.4f}, F1 {svm_f1:.4f}, ROC-AUC {svm_roc:.4f}\")\n",
    "print(\"PCA-based shallow NN acc:\", acc_pca, \" raw-pixel NN acc:\", acc_raw)\n",
    "\n",
    "print(\"\\nSaved plots (lab10_plots/):\")\n",
    "saved = [\n",
    " \"loss.png\", \"valacc.png\", \"sample_preds.png\",\n",
    " \"sin_fit.png\", \"loss.png\",\n",
    " \"sequence_similarity.png\",\n",
    " \"roc_class0.png\",\n",
    " \"feature_comp.png\"\n",
    "]\n",
    "for p in saved: print(\"lab10_plots/\" + p)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30.119868,
   "end_time": "2025-08-29T16:41:23.497846",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-29T16:40:53.377978",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
